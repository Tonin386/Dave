{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ce79d1",
   "metadata": {},
   "source": [
    "# Dave - Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdecca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as cp\n",
    "import cupy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f400737",
   "metadata": {},
   "source": [
    "## Etape 1 - Chargement des données dans un tableau NumPy (ici CuPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96255898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    dfs = []\n",
    "    basePath = \"original_data/\"\n",
    "    zone_labels = os.listdir(basePath)\n",
    "    for z in enumerate(zone_labels):\n",
    "        df = pd.DataFrame()\n",
    "        measures = os.listdir(basePath + z[1])\n",
    "        for i in range(len(measures)):\n",
    "            measures[i] = int(measures[i].replace(\".json\", \"\"))\n",
    "        for m in sorted(measures):\n",
    "            with open(basePath +  z[1] + \"/\" + str(m) + \".json\", \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                for k in data:\n",
    "                    data[k] = data[k][\"signalStrength\"]\n",
    "                    data[k] = [np.nan if v is None else v for v in data[k]]\n",
    "                    data[k] = np.array(data[k], dtype=float).get()\n",
    "            jDf = pd.Series(data)\n",
    "            df = pd.concat([df, jDf], axis=1)\n",
    "        dfs.append(df)\n",
    "        dfs[-1].columns = range(30)\n",
    "        \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a561d85",
   "metadata": {},
   "source": [
    "On en profite pour définir des paramètres importants pour notre modèle d'apprentissage, comme le nombre de salles, de réseaux, de positions mesurées et d'acquisitions par position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641357e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = loadData()\n",
    "nb_networks = 60\n",
    "nb_rooms = len(dfs)\n",
    "nb_acq = 20\n",
    "nb_positions = 30\n",
    "nb_measures = nb_acq * nb_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2c4b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = np.zeros([nb_rooms, nb_networks, nb_positions, nb_acq], dtype=\"float64\")\n",
    "for k in range(len(dfs)):\n",
    "    a = dfs[k].to_numpy()\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a[i])):\n",
    "            if(len(a[i][j]) > 20):\n",
    "                values[k][i][j] = np.array(a[i][j][(len(a[i][j]) - nb_acq):], dtype=\"float64\")\n",
    "            else:\n",
    "                values[k][i][j] = np.array(a[i][j], dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2fc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = np.nanmin(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f31dd",
   "metadata": {},
   "source": [
    "## Etape 2 - Analyse des données manquantes pour le choix des réseaux utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f08f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22.02 -59.55\n",
      "1 7.52 -62.21\n",
      "2 7.50 -62.00\n",
      "3 8.67 -63.78\n",
      "4 7.80 -63.96\n",
      "5 13.13 -56.59\n",
      "6 13.17 -56.61\n",
      "7 13.18 -56.74\n",
      "8 4.27 -57.76\n",
      "9 41.15 -83.47\n",
      "10 58.88 -81.58\n",
      "11 58.52 -81.85\n",
      "12 58.53 -81.81\n",
      "13 26.18 -82.77\n",
      "14 29.20 -82.58\n",
      "15 30.82 -82.71\n",
      "16 21.18 -82.79\n",
      "17 47.82 -84.63\n",
      "18 77.40 -81.12\n",
      "19 77.55 -81.40\n",
      "20 77.07 -81.36\n",
      "21 22.00 -81.59\n",
      "22 24.17 -81.42\n",
      "23 23.30 -81.42\n",
      "24 25.27 -81.40\n",
      "25 87.38 -83.32\n",
      "26 87.35 -82.83\n",
      "27 87.62 -83.42\n",
      "28 88.65 -82.87\n",
      "29 83.83 -85.91\n",
      "30 82.28 -86.34\n",
      "31 84.40 -85.78\n",
      "32 85.60 -85.62\n",
      "33 44.18 -81.40\n",
      "34 3.25 -63.62\n",
      "35 3.33 -65.59\n",
      "36 3.30 -65.65\n",
      "37 3.33 -65.60\n",
      "38 4.38 -55.63\n",
      "39 11.50 -54.79\n",
      "40 8.32 -55.09\n",
      "41 3.28 -57.71\n",
      "42 34.40 -82.61\n",
      "43 53.98 -80.92\n",
      "44 52.83 -81.12\n",
      "45 54.18 -81.02\n",
      "46 17.43 -83.02\n",
      "47 20.45 -82.87\n",
      "48 16.90 -83.48\n",
      "49 100.00 nan\n",
      "50 72.15 -82.63\n",
      "51 76.08 -82.21\n",
      "52 73.48 -82.21\n",
      "53 77.32 -81.53\n",
      "54 14.78 -82.18\n",
      "55 27.95 -82.00\n",
      "56 27.52 -81.77\n",
      "57 28.93 -81.93\n",
      "58 13.95 -80.10\n",
      "59 80.95 -75.69\n",
      "[25, 26, 27, 28, 29, 30, 31, 32, 49]\n"
     ]
    }
   ],
   "source": [
    "useless_networks = []\n",
    "networks_labels = []\n",
    "for k in range(len(values[0])):\n",
    "    mean = np.nanmean(values[:,k])\n",
    "    rate = np.count_nonzero(np.isnan(values[:, k])) / (nb_rooms*nb_measures) * 100\n",
    "    print(k, \"%.2f\" % rate, \"%.2f\" % mean)\n",
    "    if rate > 80 and (mean < -80 or np.isnan(mean)):\n",
    "        useless_networks.append(k)\n",
    "    else:\n",
    "        networks_labels.append(dfs[0].index[k])\n",
    "        \n",
    "print(useless_networks)\n",
    "nb_networks -= len(useless_networks)\n",
    "values = np.array(cp.delete(np.asnumpy(values), useless_networks, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112ff3c3",
   "metadata": {},
   "source": [
    "## Etape 3 - Traitement des données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1e0c5",
   "metadata": {},
   "source": [
    "Dans le cas où les données manquantes le sont en masse par position (> 80%), on les remplace par la valeur minimum mesurée sur l'entièreté des mesures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5711fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(values)):\n",
    "    for j in range(len(values[i])):\n",
    "        for k in range(len(values[i][j])):\n",
    "            rate = np.count_nonzero(np.isnan(values[i][j][k])) / len(values[i][j][k]) * 100\n",
    "            if rate > 80:\n",
    "                values[i][j][k][np.isnan(values[i][j][k])] = min_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea5c3c",
   "metadata": {},
   "source": [
    "Dans le cas où il y a peu de données manquantes par position, on remplace les données manquantes par la moyenne des données de la position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54b2b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(values)):\n",
    "    for j in range(len(values[i])):\n",
    "        for k in range(len(values[i][j])):\n",
    "            rate = np.count_nonzero(np.isnan(values[i][j][k])) / len(values[i][j][k]) * 100\n",
    "            if rate < 30:\n",
    "                values[i][j][k][np.isnan(values[i][j][k])] = int(np.nanmean(values[i][j][k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0541c8e2",
   "metadata": {},
   "source": [
    "On enlève la dimension \"position\" dans la salle, les données ne sont plus triées que par salle, par réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748e1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.reshape(values, [nb_rooms, nb_networks, nb_measures])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d24ddf0",
   "metadata": {},
   "source": [
    "Les dernières données manquantes sont remplacées par la moyenne des valeurs par réseau par salle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feee0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(values)):\n",
    "    for j in range(len(values[i])):\n",
    "        values[i][j][np.isnan(values[i][j])] = int(np.nanmean(values[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aafbf4",
   "metadata": {},
   "source": [
    "## Etape 4 - Traitement des données aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ef633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2673202614379087 % of outliers replaced\n"
     ]
    }
   ],
   "source": [
    "alpha = 3\n",
    "total_outliers = 0\n",
    "for i in range(len(values)):\n",
    "    for j in range(len(values[i])):\n",
    "        mean = np.mean(values[i][j])\n",
    "        std = np.std(values[i][j])\n",
    "        outliers = values[i][j][abs(values[i][j] - mean) > alpha * std]\n",
    "        if len(outliers) > 0:\n",
    "            total_outliers += len(outliers)\n",
    "            values[i][j][values[i][j] > mean + alpha * std] = int(mean + alpha * std)\n",
    "            values[i][j][values[i][j] < mean - alpha * std] = int(mean - alpha * std)\n",
    "            \n",
    "print((total_outliers / (nb_rooms * nb_networks * nb_measures)) * 100, '% of outliers replaced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b18f72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((nb_networks+1, nb_measures*nb_rooms))\n",
    "networks_labels.append(\"Labels\")\n",
    "for i in range(len(values)):\n",
    "    data[:,i*nb_measures:(i+1)*nb_measures] = np.append(values[i], np.array([[i]] * nb_measures).T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a6d5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data.T.get())\n",
    "data_df.to_csv(\"cleaned_data.csv\", header=networks_labels, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
